{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOB1u183Uh6AVKDFZJj345c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackiemacguire/learning-archive/blob/main/PyTorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "qumw6xp-2BrD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors\n",
        "\n",
        "\n",
        "Created using 'torch.Tensor()'"
      ],
      "metadata": {
        "id": "dN3i0vDJ2iRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "#scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar\n",
        "\n",
        "#number of dimensions\n",
        "scalar.ndim\n",
        "\n",
        "#Get tensor back as Python int\n",
        "scalar.item()\n",
        "\n",
        "#Vector (magnitude and direction)\n",
        "vector = torch.tensor([7,7])\n",
        "vector\n",
        "\n",
        "vector.ndim\n",
        "\n",
        "vector.shape\n",
        "torch.Size([2])\n",
        "\n",
        "#MATRIX\n",
        "MATRIX = torch.tensor([[7,8],\n",
        "                       [9,10]])\n",
        "MATRIX\n",
        "\n",
        "MATRIX.ndim\n",
        "\n",
        "MATRIX[1]\n",
        "\n",
        "MATRIX.shape\n",
        "\n",
        "#TENSOR\n",
        "TENSOR = torch.tensor([[[1,2,3],\n",
        "                        [3,5,6],\n",
        "                        [2,4,5]]])\n",
        "TENSOR\n",
        "\n",
        "TENSOR.ndim\n",
        "TENSOR.shape\n",
        "TENSOR[0]\n",
        "\n",
        "\n",
        "#Random Tensors -> important because neural networks start learning\n",
        "#with tensors full of random numbers and then adjust to better\n",
        "#represent the data\n",
        "\n",
        "#starts with random nums -> looks at data ->\n",
        "#updates random nums -> looks at data -> updates random nums\n",
        "\n",
        "#Create Random Tensor of size(3,4)\n",
        "#https://docs.pytorch.org/docs/stable/generated/torch.rand.html\n",
        "random_tensor = torch.rand(3,4)\n",
        "random_tensor\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZDdr6TO2kyY",
        "outputId": "1236196e-88c0-45b9-8378-9ec964acb039"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7917, 0.6678, 0.7520, 0.7440],\n",
              "        [0.0516, 0.5040, 0.2135, 0.3548],\n",
              "        [0.8176, 0.0619, 0.1527, 0.9147]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.ndim\n",
        "\n",
        "#create a random tensor with similar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(224,224,3))#height, width, color channels (R,G,B)\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxyPR1T3z8S7",
        "outputId": "1f39afe0-e6ff-41dd-c3e4-c9962be772ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tensor of all 0's\n",
        "zeros= torch.zeros(3,3)\n",
        "zeros\n",
        "\n",
        "#dtype stands for data type\n",
        "zeros.dtype\n",
        "\n",
        "random_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umu9R9-60-6H",
        "outputId": "f2038722-6e9d-4c3c-c91f-204374516d05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a range of tensors and tensors-like\n",
        "# use torch.arange()\n",
        "\n",
        "one_to_twenty = torch.arange(1,21)\n",
        "one_to_twenty\n",
        "steps = torch.arange(start=0, end=200,step=8)\n",
        "steps\n",
        "\n",
        "#creating tensors like\n",
        "twenty_zeros = torch.zeros_like(input=one_to_twenty)\n",
        "twenty_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wglG6sYp1oXI",
        "outputId": "fb909e01-3581-452d-9035-b261a8ba7e79"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor datatypes\n",
        "# https://docs.pytorch.org/docs/stable/tensors.html\n",
        "#Precision in Computing\n",
        "\n",
        "#Float 32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, #what datatype is the tensor\n",
        "                               device=None, #What device is tensor on\n",
        "                               requires_grad=False) #whether or not to track gradients with this tensors operations\n",
        "\n",
        "float_32_tensor\n",
        "\n",
        "#Getting info from Tensors\n",
        "#to get datatype from tensor use tensor.dtype\n",
        "#to get shape use tensor.shape\n",
        "#to get device use tensor.device\n",
        "\n",
        "#print to find details\n",
        "print(f\"datatype: {random_tensor.dtype}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt-u9_mI2tg1",
        "outputId": "fe5b0b2d-413f-485c-b8cb-525aa0f762f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datatype: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor Operations (addition, subtraction, multiplacation (element-wise) division. matrix multiplication)\n",
        "tensor=torch.tensor([1,2,3])\n",
        "tensor+20 #adds 20 to each value in []\n",
        "\n",
        "tensor-50 #subtracts 50\n",
        "\n",
        "tensor*2 #multiplies by 2\n",
        "\n",
        "#Using PyTorch built-in functions\n",
        "torch.mul(tensor, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcGm0fa8I702",
        "outputId": "d7be1216-e88c-48a1-9b81-7253ed6c535d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Matrix Multiplication (dot product)\n",
        "\n",
        "#Two main ways of multiplting in neural natworks and deep learning\n",
        "  # element wise ie 2*[1,2,4]\n",
        "  # matrix mult (or dot product) --> row x col and add up\n",
        "\n",
        "#Element wise mult\n",
        "print(tensor, \"*\", tensor)\n",
        "print(f\"Equals: {tensor * tensor}\")\n",
        "\n",
        "#matrix mult\n",
        "torch.matmul(tensor, tensor)\n",
        "\n",
        "\n",
        "#Common errors in deep learning is shape error\n",
        "#Two rules for matrix mult\n",
        "#INNER dimensions must match :\n",
        "# (3x2) and (3x2) won't work --> 2 and 3 don't match\n",
        "# (3,2) and (2,3) will work --> 2 and 2 match\n",
        "\n",
        "#The RESULTING matrix shape is the OUTER dimensions\n",
        "# so the working example above resultant matrix will be 3x3\n",
        "\n",
        "tensor_A = torch.tensor([[1,2],\n",
        "                          [3,4],\n",
        "                          [5,6]])\n",
        "tensor_B = torch.tensor([[5,2],\n",
        "                          [3,7],\n",
        "                          [6,6]])\n",
        "tensor_B, tensor_B.shape\n",
        "\n",
        "tensor_B.T, tensor_B.T.shape\n",
        "\n",
        "\n",
        "#This operation now works because tensor_B is transposed\n",
        "\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
        "torch.matmul(tensor_A, tensor_B.T)\n",
        "#To fix our tensor shape issues, we can manipulate the shape\n",
        "#of one of our tensors using a TRANSPOSE--> switches the axes\n",
        "#or dimensions of a given tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnGnDd4sNrqk",
        "outputId": "b34fa859-6122-488a-fbed-bc1f85c3dd4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n",
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 9, 17, 18],\n",
              "        [23, 37, 42],\n",
              "        [37, 57, 66]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the min, max, mean, sum, etc (tensor aggregation)\n",
        "\n",
        "# create a tensor\n",
        "x= torch.arange(0,100,10)\n",
        "x\n",
        "\n",
        "#find max\n",
        "torch.max(x), x.max()\n",
        "\n",
        "# mean ** torch.mean() requires a tensor of float32 dtype\n",
        "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()\n",
        "\n",
        "#Finding positional min and max\n",
        "# use argmin() for min ** it will return the index of the minimum\n",
        "x.argmin()\n",
        "#to get the specific value\n",
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkWVQBIy-spb",
        "outputId": "e5cfcb26-b216-4796-fc68-6df06df66c84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "# reshaping - reshapes an input tensor to a defined shape\n",
        "# View - return a view of an input tensor of certain shapes but keeps the same memory as the og tensor\n",
        "# stacking - combines multiple tensors on top of each other (vstack) or side by side (hstack)\n",
        "# squeeze - removes all '1' dimensions from tensor\n",
        "# unsqueeze - adds '1' dimension to a target tensor\n",
        "# Permute - returns a view of the input with dimensions swapped in a certain way\n",
        "\n",
        "\n",
        "x = torch.arange(1.,10.)\n",
        "x, x.shape\n",
        "\n",
        "# add an extra dimension\n",
        "x_reshaped = x.reshape(9,1)\n",
        "x_reshaped, x_reshaped.shape\n",
        "\n",
        "# change view\n",
        "z = x.view(1,9)\n",
        "z, z.shape\n",
        "\n",
        "# changing z changes x bc a view of a tensor shares the same memory as the og input\n",
        "z[:, 0]=5\n",
        "z,x\n",
        "\n",
        "#Stack tensor on top of each other\n",
        "x_stacked = torch.stack([x,x,x,x], dim=0)\n",
        "x_stacked\n",
        "\n",
        "# torch.squeeze() removes all single dimensions from a target tensor\n",
        "x_reshaped.squeeze()\n",
        "\n",
        "x_reshaped.squeeze().shape\n",
        "\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "\n",
        "# torch.unsqueeze()- adds a single dimension to a target tensor at a specific dim\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(x_unsqueezed)\n",
        "\n",
        "\n",
        "#torch.permute() - rearrange dimensions\n",
        "\n",
        "x_og = torch.rand(size=(224,224,3)) # heights width, color_channels\n",
        "\n",
        "#permute the og tensor to rearrange the axis (or dim) order\n",
        "x_permuted = x_og.permute(2,0,1) #shifts axis 0--> 1, 1-->2, 2-->0\n",
        "\n",
        "x_og[0,0,0] = 728000\n",
        "x_og[0,0,0], x_permuted[0,0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APaaBwwpA4Of",
        "outputId": "459da37d-f388-4684-c90a-dbd462d6a64f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(728000.), tensor(728000.))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Selecting data from tensors (Indexing)\n",
        "\n",
        "x = torch.arange(1,10).reshape(1,3,3)\n",
        "x, x.shape\n",
        "\n",
        "#Let's index on our new tensor\n",
        "x[0]\n",
        "\n",
        "#Let's index on the middle bracket (dim=1)\n",
        "x[0][0]\n",
        "\n",
        "#Let's index on the most inner (last dim)\n",
        "x[0][1][1]\n",
        "\n",
        "#You can also use \":\" to select 'all' of a target dimension\n",
        "\n",
        "x[:,0]\n",
        "\n",
        "# Get all values of the 0th and 1st dimensions but only index 1 of 2nd dimension\n",
        "x[:,:,1]\n",
        "\n",
        "#Get all the values of the 0 dim but only the 1 index value of 1st and 2nd dimension\n",
        "x[:,1,1]\n",
        "\n",
        "#Get index 0 of 0th and 1st dimension and all values of 2nd dim\n",
        "x[0, 0, :]\n",
        "\n",
        "#Index on x to return last # in this matrix\n",
        "print(x[0][2][2])\n",
        "\n",
        "#Index on x to return last column\n",
        "print(x[:,:,2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgOQfdgqkF-S",
        "outputId": "ff493e9f-a9be-4fd5-bc7e-ef1d68ed915e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9)\n",
            "tensor([[3, 6, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PyTorch tensors and NumPy (numerical computing library)\n",
        "#data in numpy, want in tensor --> torch.from_numpy(ndarray)\n",
        "#PyTorch tensore -> numpy -> torch.Tensor.numpy()\n",
        "\n",
        "import numpy as np\n",
        "array = np.arange(1.0,8.0)\n",
        "tensor = torch.from_numpy(array) #WARNING: converting from numpy-> pytorch, pytorch rejects numpy's default datatype of float64 unless specified\n",
        "array, tensor\n",
        "\n",
        "#tensor.dtype // what will happen to tensor if we change the value of array\n",
        "array = array + 1\n",
        "\n",
        "array, tensor\n",
        "\n",
        "torch.arange(1.0, 8.0).dtype\n",
        "\n",
        "#Tensor to NumPy array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor\n",
        "\n",
        "numpy_tensor.dtype\n",
        "\n",
        "#Change tensor, what happens to 'numpy_tensor'\n",
        "tensor = tensor +1\n",
        "tensor, numpy_tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9bhHLNnoCr9",
        "outputId": "649ba154-2eb7-4c11-e3a5-e2d0598ba1ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reproducbility (trying to take random out of random)\n",
        "\n",
        "#to reduce randomness: Random seed --> it initializes the random number generator\n",
        "\n",
        "random_tensor_A= torch.rand(3,4)\n",
        "random_tensor_B=torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A == random_tensor_B)\n",
        "\n",
        "\n",
        "#random but redproducible tensors\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3,4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C == random_tensor_D)\n",
        "\n",
        "#REPRODUCIBILITY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6LyxFn3qTcV",
        "outputId": "cec71917-ba20-460b-a7a3-1bb0db247404"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6189, 0.9531, 0.4133, 0.6765],\n",
            "        [0.2546, 0.1429, 0.9983, 0.3258],\n",
            "        [0.8146, 0.7345, 0.7681, 0.4564]])\n",
            "tensor([[0.7052, 0.9378, 0.0813, 0.5049],\n",
            "        [0.2976, 0.5322, 0.5927, 0.6138],\n",
            "        [0.1362, 0.8695, 0.5829, 0.5610]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Running tensors and PyTorch objects on the GPUs (and making them faster computations)\n",
        "#GPUs = faster computation on numbers thanks to CUDA and NVIDIA hardware\n",
        "# can use google colab, colab pro, or buy your own, or cloud computing like AWS, Azure\n",
        "\n",
        "# GPU access\n",
        "torch.cuda.is_available()\n",
        "\n",
        "#Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "\n",
        "#count num of devices\n",
        "torch.cuda.device_count()\n",
        "\n",
        "#Putting tensors / models on gpu is bc it results in faster computations\n",
        "#Create a tensor (default in cpu)\n",
        "tensor = torch.tensor([1,2,3])\n",
        "\n",
        "#Tensor not on GPU\n",
        "print(tensor, tensore.device)\n",
        "\n",
        "#move tensor to gpu (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu.numpy()\n",
        "#if tensor is on gpu, cant transform it to NumPy\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu\n",
        "tensor_on_gpu\n"
      ],
      "metadata": {
        "id": "fEogZTXb__Tj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
